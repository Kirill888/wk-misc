{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import (\n",
    "    Client, \n",
    "    progress as dask_progress,\n",
    "    wait as dask_wait,\n",
    ")\n",
    "import os\n",
    "import dask\n",
    "\n",
    "# configure dashboard link to go over proxy\n",
    "dask.config.set({\"distributed.dashboard.link\":\n",
    "                 os.environ.get('JUPYTERHUB_SERVICE_PREFIX', '/')+\"proxy/{port}/status\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.rio import configure_s3_access\n",
    "\n",
    "client = Client('tcp://dask-scheduler:8786')\n",
    "display(client)\n",
    "\n",
    "if False:\n",
    "    client.restart()\n",
    "\n",
    "if not client.get_metadata('odc_s3', False):\n",
    "    # Configure GDAL for s3 access\n",
    "    print('Configuring S3 read')\n",
    "    configure_s3_access(aws_unsigned=True,  # works only when reading public resources\n",
    "                        client=client)\n",
    "    client.set_metadata('odc_s3', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import s2gm\n",
    "from datacube.utils.dask import compute_tasks\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "cfg = s2gm.load_config('gmcfg.toml')\n",
    "tasks_pkl = Path(f'tasks_{cfg.year}_{cfg.season}.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tasks = pickle.load(gzip.open(tasks_pkl, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.aws import s3_client, s3_fetch, auto_find_region\n",
    "import time\n",
    "from distributed import wait as dask_wait\n",
    "import toolz\n",
    "import distributed\n",
    "\n",
    "region = auto_find_region()\n",
    "s3 = s3_client(creds=cfg.s3.creds, region_name=region)\n",
    "\n",
    "def s3_file_exists(url, s3):\n",
    "    try:\n",
    "        bb = s3_fetch(url, range=(0,4), s3=s3)\n",
    "        return len(bb) > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def task_should_skip(task):\n",
    "    y_url = cfg.s3.prefix + task.dataset_prefix + task.file_prefix + '.yaml'\n",
    "    return s3_file_exists(y_url, s3=s3)\n",
    "    \n",
    "\n",
    "def is_persist_done(x, timeout=0.01):\n",
    "    try:\n",
    "        dask_wait(x, timeout=timeout)\n",
    "        return True\n",
    "    except distributed.TimeoutError as e:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def mk_futures(tasks, n_active=3, delay=0):\n",
    "    tasks = (task for task in tasks if not task_should_skip(task))\n",
    "    \n",
    "    def stage1(tasks):\n",
    "        for task in tasks:\n",
    "            if delay:\n",
    "                time.sleep(delay)\n",
    "                \n",
    "            xx, gm, yaml = s2gm.process_task(task, cfg, client)\n",
    "            yaml = client.compute(yaml)\n",
    "            del xx\n",
    "            yield (gm, yaml)\n",
    "\n",
    "    inprogress = []\n",
    "\n",
    "    for (gm, yaml) in stage1(tasks):\n",
    "        inprogress.append((gm, yaml))\n",
    "        \n",
    "        while True:\n",
    "            todo = []\n",
    "            for (gm, yaml) in inprogress:\n",
    "                if is_persist_done(gm, 0.1):\n",
    "                    print('.', end='')\n",
    "                    del gm\n",
    "                    yield yaml\n",
    "                else:\n",
    "                    todo.append((gm, yaml))\n",
    "            inprogress = todo\n",
    "            if len(inprogress) <= n_active:\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_futures = []\n",
    "\n",
    "for f in mk_futures(tqdm(tasks), 6, delay=5):\n",
    "    yy_futures.append(f)\n",
    "    \n",
    "    y_done = []\n",
    "    y_todo = []\n",
    "    for y in yy_futures:\n",
    "        if y.done():\n",
    "            y_done.append(y)\n",
    "        else:\n",
    "            y_todo.append(y)\n",
    "    yy_futures = y_todo\n",
    "    \n",
    "    for y in y_done:\n",
    "        try:\n",
    "            url, ok = y.result()\n",
    "            print(f'{url} {ok}')\n",
    "        except Exception as e:\n",
    "            print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
