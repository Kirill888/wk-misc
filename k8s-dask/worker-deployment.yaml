apiVersion: apps/v1
kind: Deployment
metadata:
  name: "dask-worker"
  labels:
    app: "dask-worker"
spec:
  replicas: 0
  selector:
    matchLabels:
      app: "dask-worker"

  template:
    metadata:
      labels:
        app: "dask-worker"
    spec:
      tolerations:
        - key: "hub.jupyter.org/dedicated"
          operator: "Equal"
          value: "worker"
          effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nodegroup
                    operator: In
                    values:
                      - sandbox
                  - key: nodetype
                    operator: In
                    values:
                      - spot
                  - key: "failure-domain.beta.kubernetes.io/zone"
                    operator: In
                    values:
                      - ap-southeast-2c

      containers:
      - name: "dask-worker"
        image: "opendatacube/sandbox:latest"
        resources:
          requests:
            cpu: "15.5"
            memory: "120Gi"
          limits:
            cpu: "15.5"
            memory: "120Gi"
        env:
        args:
          - bash
          - "-c"
          - |
              LIBS="odc-algo odc-index datacube odc-ui"
              pip install \
                --upgrade \
                --extra-index-url="https://packages.dea.ga.gov.au" \
                --no-deps \
                $LIBS

              dask-worker \
                --nthreads=16 \
                --memory-limit=120Gi \
                --worker-port=11911 \
                --nanny-port=11912 \
                --dashboard-address=0:11913 \
                --reconnect \
                tcp://dask-scheduler:8786

        ports:
          - containerPort: 11911
          - containerPort: 11912
          - containerPort: 11913
