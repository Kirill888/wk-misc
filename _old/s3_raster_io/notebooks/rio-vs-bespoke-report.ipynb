{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bespoke S3 TIFF reader\n",
    "\n",
    "Rather than using rasterio/GDAL we have custom reader that uses `botocore` to fetch data from S3 bucket, parses tif header, then reads requested chunk. Overall this equates to 2 requests per image when doing pixel drill type access.\n",
    "\n",
    "Reader limitations:\n",
    "\n",
    "- Tiled images only (COG only)\n",
    "- DEFLATE compression only\n",
    "- No predictor (expect to add, as it's common with 16bit images)\n",
    "- Only reads band 1 (easy to add support for multi-band images)\n",
    "- Doesn't interpret GEO referencing data\n",
    "\n",
    "## Experiment Setup\n",
    "\n",
    "- Wofs LS5, full history query\n",
    "- Tile -9 -18, chunk (8,2)\n",
    "- Image Properties\n",
    "    - 4000x4000 single band uint8\n",
    "    - Chunk size 256x256\n",
    "    - No pixel differencing applied before compressing\n",
    "    - ZIP (level 9) with GeoTiff only metadata\n",
    "- 1416 time slices\n",
    "- Access one chunk from each time slice\n",
    "- M5.xlarge instance 4 cores 16G ram\n",
    "- Chunk with largest compressed size was chosen\n",
    "- S3 bucket and EC2 both in Sydney region\n",
    "- \"Random\" 5-char prefix added to file names\n",
    "- Data location\n",
    "    - http://dea-public-data.s3-website-ap-southeast-2.amazonaws.com/?prefix=bench-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils import bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['./results/M5XL_ZIP2R_-9_-18b8_2B1__01_001.pickle',\n",
    "        './results/M5XL_ZIP2_-9_-18b8_2B1__01_001.pickle',\n",
    "        './results/M5XL_ZIP2R_-9_-18b8_2B1__16_001.pickle', ## fastest total completion\n",
    "        './results/M5XL_ZIP2_-9_-18b8_2B1__20_001.pickle',  ## fastest total completion\n",
    "        ]\n",
    "dd = [pickle.load(open(file, 'rb')) for file in files]\n",
    "sts = [bench.unpack_stats(d, ms=True) for d in dd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison GDAL vs Bespoke (single thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = (bench.gen_stats_report(dd[0], 'GDAL'),\n",
    "           bench.gen_stats_report(dd[1], 'BESPOKE'))\n",
    "print(bench.join_reports(*reports))\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "bench.plot_comparison(fig, sts[:2], \n",
    "                      names=['GDAL', 'BESPOKE'], \n",
    "                      threshs=[400, 250, 80],\n",
    "                      nochunk=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison GDAL vs Bespoke (fastest parallel run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = (bench.gen_stats_report(dd[2], 'GDAL'),\n",
    "           bench.gen_stats_report(dd[3], 'BESPOKE'))\n",
    "print(bench.join_reports(*reports))\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "bench.plot_comparison(fig, sts[2:4], \n",
    "                      names=['GDAL', 'BESPOKE'], \n",
    "                      threshs=[400, 250, 80],\n",
    "                      nochunk=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Using bespoke implementation we are able to reduce number of S3 get requests compared to GDAL implementation and as a result have a significantly faster load time overall (more than **2 times** faster, in parallel case, **61%** reduction of total latency).\n",
    "\n",
    "Single thread peformance is **36.7%** faster for bespoke implementation, but more importantly parallell scaling is better for bespoke approach (due to fewer S3 GET requests), as a result bespoke appoach completes in **5.82s** in the fastest case using 20 threads, while GDAL implementation achieves **14.96s** fastest time using 16 threads.\n",
    "\n",
    "Bespoke appoach is siginificantly faster when reading image header, but quite a bit slower when reading pixel data. This could be due to fairly un-optimized data retrieval code that does more data copies than neccessary: `http -> zlib -> temp -> numpy`, it's fairly simple to implement custom decompress pipeline that extracts data directly into it's final destination avoding an extra copy.\n",
    "\n",
    "## Future work\n",
    "\n",
    "Using bespoke TIF reader allows further experimentation\n",
    "\n",
    "- Caching image metadata in some DB and hence avoid loading header data at all, potentially halving access time\n",
    "- Use AsyncIO instead of multi-threading, or in combination with multi-threading to achieve higher IO performance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
