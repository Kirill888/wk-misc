{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to obtain full listing of the nrt data:\n",
    "\n",
    "```bash\n",
    "s3-find 's3://dea-public-data/L2/sentinel-2-nrt/S2MSIARD/**/*' | tee /dev/stderr | gzip -9 > s2nrt.txt.tgz\n",
    "```\n",
    "\n",
    "Code below will groups these paths into datasets using S2 specific path pattern:\n",
    "\n",
    "```\n",
    "{s3_prefix}/{date:day precision}/{dataset_dir}/...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import gzip\n",
    "from itertools import islice\n",
    "import tqdm\n",
    "from types import SimpleNamespace\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "\n",
    "def get_paths(f, prefix=''):\n",
    "    skip = len(prefix)\n",
    "    for line in f:\n",
    "        line = line.decode('utf8').rstrip('\\n')\n",
    "        line = line[skip:]\n",
    "        yield line\n",
    "\n",
    "def path_split(s):\n",
    "    try:\n",
    "        date, ds, *fp = s.split('/')\n",
    "    except ValueError:\n",
    "        print(f'Bad: \"{s}\"')\n",
    "        return (None, None, None)\n",
    "    \n",
    "    return (date, ds, '/'.join(fp))\n",
    "\n",
    "def load_from_gz(fname, prefix, verbose=True):\n",
    "    oo = SimpleNamespace(ds_per_day={}, files_per_ds={})\n",
    "    \n",
    "    with gzip.open(fname, 'rb') as gz_src:\n",
    "        dss = map(path_split, get_paths(gz_src, prefix))\n",
    "        \n",
    "        if verbose:\n",
    "            dss = tqdm.tqdm_notebook(dss)\n",
    "        \n",
    "        for (day, ds, fname) in dss:\n",
    "            if day is None:\n",
    "                continue\n",
    "                \n",
    "            ds_key = f'{day}/{ds}'\n",
    "            if fname == 'ARD-METADATA.yaml':\n",
    "                oo.ds_per_day[day] = oo.ds_per_day.get(day, 0) + 1\n",
    "        \n",
    "            oo.files_per_ds.setdefault(ds_key, []).append(fname)\n",
    "    \n",
    "    return oo\n",
    "\n",
    "def compute_stats(oo, expect_count=None):\n",
    "    ds_per_day = oo.ds_per_day\n",
    "    files_per_ds = oo.files_per_ds\n",
    "    \n",
    "    count_by_day = sorted((d,c) for d,c in ds_per_day.items())\n",
    "\n",
    "    tt = np.asarray([d for d,_ in count_by_day], dtype='datetime64[s]')\n",
    "    cc = np.asarray([c for _,c in count_by_day], dtype='uint32')\n",
    "    ds_count = xr.DataArray(cc, \n",
    "                            dims=('time',), \n",
    "                            coords=dict(time=tt), \n",
    "                            name='ds_count')\n",
    "    \n",
    "    oo.ds_count = ds_count\n",
    "    oo.total_ds = ds_count.sum().data.item()\n",
    "    oo.total_ds_dirs = len(files_per_ds)\n",
    "    oo.no_yaml_dirs = {k:v for k,v in files_per_ds.items() if 'ARD-METADATA.yaml' not in v}\n",
    "    \n",
    "    if expect_count is not None:\n",
    "        skip_set = set(oo.no_yaml_dirs)\n",
    "        oo.other_bad = {\n",
    "            k:v \n",
    "            for k,v in files_per_ds.items() if len(v) != expect_count and k not in skip_set\n",
    "        }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = 's3://dea-public-data/L2/sentinel-2-nrt/S2MSIARD/'\n",
    "http_prefix = s3_prefix.replace('s3://dea-public-data/', 'https://data.dea.ga.gov.au/?prefix=')\n",
    "n_expect=64\n",
    "file_list_gz='s2nrt.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s3 = load_from_gz(file_list_gz, s3_prefix, verbose=True)\n",
    "compute_stats(s3, n_expect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing_yamls = s3.total_ds_dirs - s3.total_ds\n",
    "n_incomplete = len(s3.other_bad)\n",
    "print(f'''Directories without yamls:\n",
    "   {n_missing_yamls:3} out of {s3.total_ds_dirs:,d}\n",
    "Directories with fewer files than expected (< {n_expect}):\n",
    "   {n_incomplete:3} out of {s3.total_ds_dirs:,d}''')\n",
    "\n",
    "if n_missing_yamls:\n",
    "    print(\"## Directories with missing yamls\")\n",
    "    for p in s3.no_yaml_dirs:\n",
    "        print(f'{http_prefix}{p}')\n",
    "\n",
    "if len(s3.other_bad) > 0:\n",
    "    print(f\"## Directories with fewer files than expected (< {n_expect})\")\n",
    "    for p in s3.other_bad:\n",
    "        print(f'{http_prefix}{p}')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(18, 6))\n",
    "ax.plot(s3.ds_count.time, s3.ds_count.data, '.', markersize=4);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
